\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[margin=0.6in]{geometry}
\title{Ph 239 Problem Set 2}
\author{Alex Zahn}
\date{4/15/2016}




\begin{document}

\maketitle

\newcommand{\wmsq}{W/\(\mathrm{m}^2\,\)}
\newcommand{\msq}{\(\mathrm{m}^2\,\)}
\newcommand{\micron}{\(\mu\mathrm{m}\)\,}
\newcommand{\mcb}{\(\mathrm{m}^3\,\)}

\section{Electric car solar panels}

\subsection{Approximate parameters}

A typical commute might be ten miles or fifteen kilometers one way.


Lead acid batteries are about \$1.25 per 12V-Ah (8.5 kJ/dollar), based on a sample of one sixty dollar, 45 Ah battery I found. However, lead acid batteries are not designed to be nearly fully discharged and can be severely damaged this way. The deeper the discharge, the more usable energy we get per battery cycle, but the fewer cycles we get. Let's say the optimal discharge is 50\% of maximum storage capacity, which is where I think most car batteries are meant to operate anyway, so let's bump the battery costs up to 17 kJ/dollar.


A typical home-use, nontracking solar array might have access to a daily average of 200 \wmsq in a building free environment and be 10\% efficent. Supposing buildings block the sun for half the day, let's say home solar panels generate 10 average-\wmsq 
 
Let's round the 4 km/kWh vehicle efficiency down by 10\% to 1 km/MJ for convenience, and keep the four dollar per peak-watt figure. Assuming a peak-watt occurs during direct sunlight of 1 k\wmsq, one average-watt of solar power costs forty dollars and requires a tenth of a square meter of collection area.

\subsection{Project costs}

We need to find 30 MJ per day for the car. At 50\% storage efficiency and 80\% charging efficiency, the solar panels need to harvest 75 MJ per day, or about 850 watts. This will cost thirty four thousand dollars, and require 85 \msq.

We need 105 MJ total of battery storage (75 MJ for the array and 30 MJ for the car). This will cost twelve thousand dollars in lead acid batteries alone, before installation, power distribution, and eventual battery replacement.

So the whole thing will run over forty five thousand dollars to build.


\section{Personal Heating}

Throughout, let's approximate the human foot as equivalent to a \(30 \times 8 \times 4\, \mathrm{cm}^3\) rectangular prism of water that is ten kelvin below body temperature. It has a volume of about one liter, and the minimum energy we need to spend is 40 kJ.

\subsection{Hot Water}

The sink's volume is probably five liters, and is initially below room temperature when it enters the house, at maybe 285 K. Heating it to a body temperature of 310 K requires at minimum 500 kJ. We might consider adding 40 kJ to the minimum value for heat lost to the foot, which might need to be replaced if we want to keep the water at an even temperature.

Supposing the home's water heater is only only 80\% efficient (maybe reasonable for a fancier modern tankless model), the cost rises to 675 kJ. Convective and evaporative heat loss to the environment might contribute something too over the several minutes we might expect this process to take, but let's assume instead we're using a carefully insulated sink and that we don't let any vapor escape, in an attempt to keep the energy estimate consistently on the low side.

So we can say this process is 6\% efficient. This number is optimistic, too, because most people will prefer to heat the water to above body temperature.

\subsection{Space heater}

To a very first approximation, let's say this process takes three minutes. Our 1.5 kW space heater consumes 300 kJ in this time, so the space heater is maybe 13\% efficient.

\subsubsection{Air-body heat transfer coefficient}

Can we be more rigorous about the amount of time this takes with a 1500 watt space heater? We could try to estimate the air-body heat transfer coefficient, by the following sketchy approximation scheme.

Experimenting with breathing on my hand, it seems reasonable to say that one two second long inhale-exhale cycle produces breath at about body temperature. Speeding up the inhale-exhale cycle to one second seems to produce qualitatively cooler breath, and slowing it down doesn't seem to do anything, so I will claim that  it takes two seconds to bring a lungful of 293 K air up to 310 K body temperature.

Next, we want the surface area to volume ratio of a lung, which we will approximate as composed exclusively of perfectly spherical alveoli. Wikipedia claims an alveolar radius of 100 \micron after normal exhalation, yielding an upper bound on the surface area to volume ratio of \(3\times10^4 \,\mathrm{\mu m}^{-1}\).

Over the course of inhalation, the alveoli will expand, and the surface area to volume ratio will drop. Again resorting to the internet, the average person's typical lung volume prior to inhaling is 2.4 L (``functional residual capacity" in lung terminology). In my tests, I think I inhaled most of a 3.6 L ``inspiratory capacity". So the lung expands from 2.4 L to 6 L, or by a factor of 2.5. The alveolar radius increases a factor of \(\sqrt[3]{2.5}\), and surface area to volume falls by the same factor, so our lower bound on surface area to volume is over 70\% of the upper bound.

So now we can almost compute an estimate of the air-body heat transfer coefficient, \(h\). Sparing ourselves some lung related differential equations, suppose all the heat flow is through a constant surface area to volume ratio \(\eta_{eff} = 2.6 \times 10^4 \,\mathrm{\mu m}^{-1}\), which is at the middle of the range we found. Getting this wrong results in an error of at most 15\% in \(h\), so it isn't useful to apply more rigor than this. Let's handwaivily do something similar with the temperature difference, and claim a \(\Delta T_{eff} = 8.5\) K, though probably introducing some nontrivial error.

So equating the heat dumped into the air by the lungs to the heat required to raise that air to body temperature, our sketchy approximation is

\[ h \Delta T_{eff} \eta_{eff} \Delta V \Delta t = \rho \Delta V c_p\Delta T
\]


Recall we raised the temperature of 6 L of air by 17 K in two seconds. Let air have a constant \(c_p = 1 \,\mathrm{J}\,\mathrm{g}^{-1}\,\mathrm{K}^{-1}\) and \(\rho = 1.2 \,\mathrm{kg}\,\mathrm{m}^{-3}\). We finally find \(h = 3\times 10^{-10}\,\mathrm{W}\,\mathrm{m}^{-2}\,\mathrm{K}^{-1}\). Clearly this is absurdly low, so something isn't right with the approach, or I made a mistake. I don't have time to take this any further though.

\subsection{Heating pad}

This might take half an hour, consuming 90 kJ, making it nearly 50\% efficient.

\subsection{Blankets}

Suppose this takes one hour. A hundred watt metabolism will consume 360 kJ, and will be a little better than 10\% efficient.


\section{}

\subsection*{a}

\(k_ee^2/Gm_em_{p} = 2.3 \times 10^{39}\)

\subsection*{b}

It seems reasonable to ignore the probably small polarizability of both objects, so this appears straightforward. We want \(k_e Z^2 e^2 = Gm_{earth}m_{moon}\), where \(Z\) is the number of atoms ionized. We find \(Z=3.6\times 10^{32}\), or \(6 \times 10^8\) mol.

Reusing approximations from the Martian terraforming problem, suppose we have a pure \(\mathrm{Si}\mathrm{O}_2\) crust. We end up ionizing \(2\times 10^8\) mol of crust, with a mass of \(10^7\) kg. If \(\mathrm{Si}\mathrm{O}_2\) has a density of \(3000 \,\mathrm{kg}/\mathrm{m}^3\), this takes up 3300 \mcb.

Surprisingly, this is a fifteen meter cube that weighs about eleven thousand tons. I would have thought it would be a lot bigger. We can't be off by much, either; certainly there's a factor of a few error in the mass and density of the crust we need, but it's suppressed by a cube root in the cube length.

\subsection*{c}

We've seen previously that a relatively easy to get neodymium magnet can generate a 1 Tesla field, which decays with \(r^{-3}\) and lifts at most around 10 kg against Earth's gravity. So the field energy density will go with \(r^{-6}\), and we expect the mass it can lift against gravity to do roughly the same. 

Earth though is a point mass \(6\times 10^6\) meters distant. What happens if we move our magnet to that distance from the mass it's trying to lift? Generously (rather gratuitously so), let's say the magnet lifted the 10 kg mass at a distance of one meter, both to simplify the numerics and to make a point. Earth's gravity would win out over the magnet for anything more massive than \(10 \,\mathrm{kg} / (6\times 10^6)^6 \approx 10^{-40} \) kg, which is one billionth the electron mass.

\section{Planck Units}

The first thing to notice is that the combination \(\hbar G\) gets rid of the mass units in \(\hbar\) and \(G\), and leaves us with a combination of length and time. It's easy to see from there 

\[ l_p = \sqrt{\frac{\hbar G}{c^3}} = 1.6 \times 10^{-35} \,\mathrm{m}
\]

The rest follow pretty easily. We would expect \(c = l_p/t_p\), so 

\[ t_p = \frac{c}{l_p} = 5.4 \times 10^{-44} \, \mathrm{s}
\]

\(\hbar\) has units of action, so it would follow

\[ E_p = \frac{\hbar}{t_p} = 2 \times 10^9 \,\mathrm{J}
\]

Lastly, 

\[ T_p = \frac{E_p}{k_B} = 1.4 \times 10^{32}\,\mathrm{K}
\]


\section{Net charge of Earth}

Suppose an asteroid collides with a planet with sufficient energy to vaporize itself on impact. What fraction of its mass is ionized? What net charge does this contribute to the planet? If Earth were formed exclusively from such impacts, and there were no processes to dissipate net charge, what net charge would Earth have just from formation?



\subsection{Sketch of a solution}

Assume the kinetic energy per atom on the asteroid is of order the chemical bond energy (as we've seen previously, about one to three eV). We might forward the possibly incorrect assumption that whatever part of the asteroid instantaneously undergoing vaporization is also locally in thermodynamic equilibrium, so that its atoms have a 1-3 eV Maxwellian velocity distribution. Out in the tail of the distribution, some fraction of atoms will have kinetic energies above 10-20 eV, where collisions start carrying enough energy to ionize them. We could assume that every atom above our cutoff energy ionizes, and ignore secondary ionization effects from the resulting electrons on the grounds that every secondary electron that a primary electron can generate costs an exponentially suppressed extra 10-20 eV.

So we can get a crude upper bound on the ionization fraction this way. This doesn't give us the net charge contributed, but we can say that it can't possibly be larger than one electron charge per ionized atom.

A better estimate of the net charge might come from noting that we're actually looking for collisions that leave one product gravitationally bound to the planet, and the other not.

Noting that an electron has Earth escape velocity at \(3.5 \times 10^{-4}\) eV, monoatomic oxygen escapes at .01 eV, and a silicate ion like \(\mathrm{Si}\mathrm{O}_2^+\) escapes near 40 eV, basically every collisional ionization has the potential to free an electron from the planet and leave behind a positive ion, since the vast majority of these events are going to involve energies only a handful of eV above the ionization energy. I could be wrong here; maybe most of the collisions are actually within a few electron escape energies of the ionization energy, and we lose a factor of two or so to scattering angle considerations.

The dominant effect is probably going to be from electrons downscattering themselves back below the escape energy. Intuition from radiation safety training says that 1 MeV beta radiation has a stopping distance in air of just a few meters, leading one to suspect not too many sub eV electrons are going to escape. Still, a realistic asteroid impact might eject a lot of mass above the atmosphere...



 
 \end{document}